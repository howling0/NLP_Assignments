{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson-01 Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 今天是2020年1月05日，今天世界上又多了一名AI工程师 :) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`各位同学大家好，欢迎各位开始学习我们的人工智能课程。这门课程假设大家不具备机器学习和人工智能的知识，但是希望大家具备初级的Python编程能力。根据往期同学的实际反馈，我们课程的完结之后 能力能够超过80%的计算机人工智能/深度学习方向的硕士生的能力。`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本次作业的内容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 复现课堂代码\n",
    "\n",
    "在本部分，你需要参照我们给大家的GitHub地址里边的课堂代码，结合课堂内容，复现内容。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 作业截止时间\n",
    "此次作业截止时间为 2020.01.12日"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 完成以下问答和编程练习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基础理论部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **评阅点**：每道题是否回答完整"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Can you come up out 3 sceneraies which use AI methods? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: Stock estimation, Extracting words from photos, Auto correction for the homeworks of online studies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. How do we use Github; Why do we use Jupyter and Pycharm;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: We could use command lines to interact with the code repositories, using commands like add, commit, push or pull to keep the code safe and control different versions.   \n",
    "Jupyter and Pycharm are coding IDEs focusing on different points, jupyter can make it easy to run the code piece by piece and observe the output directly, with the help of markdown, it can be a efficient tool for experiments or demonstration; and Pycharm is a powerful coding tool with convenient functions and comprehensive hints and code complement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. What's the Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: It refers modeling questions and solve problems based on probability and statistics, instead of artificial rules summarized by specialists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Can you came up with some sceneraies at which we could use Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: Voice recognition; sorting the pages in online search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Why do we use probability and what's the difficult points for programming based on parsing and pattern match?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: Because there are too many patterns to be summarized, and some of them are continuously changing and transforming, the specialists can never get all of them. Whereas using probability is more like a data based method which can deal with more different inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. What's the Language Model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: Modeling language based on probability, normally used to generate sentences, or check wether a sentence is reasonable by giving the probability of the sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Can you came up with some sceneraies at which we could use Language Model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: Poem auto generation; input correction; auto marking essay homeworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. What's the 1-gram language model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:Calculating the probability of every single words and multiply them together to get the probability of the sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. What's the disadvantages and advantages of 1-gram language model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:  \n",
    "Advantages: Easier to calculate, just need to count the number of occurrence.  \n",
    "Disadvantages: The result is not considering the context of each word at all, it might miss some important information, like negativity around a positive word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. What't the 2-gram models;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 2-gram models assume each word only depends on the one word ahead of it, and get the probability of the sentence by calculating the conditional probabilities of each words, except the first one, and multiply them together for the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编程实践部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 设计你自己的句子生成器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如何生成句子是一个很经典的问题，从1940s开始，图灵提出机器智能的时候，就使用的是人类能不能流畅和计算机进行对话。和计算机对话的一个前提是，计算机能够生成语言。\n",
    "\n",
    "计算机如何能生成语言是一个经典但是又很复杂的问题。 我们课程上为大家介绍的是一种基于规则（Rule Based）的生成方法。该方法虽然提出的时间早，但是现在依然在很多地方能够大显身手。值得说明的是，现在很多很实用的算法，都是很久之前提出的，例如，二分查找提出与1940s, Dijstra算法提出于1960s 等等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在著名的电视剧，电影《西部世界》中，这些机器人们语言生成的方法就是使用的SyntaxTree生成语言的方法。\n",
    "\n",
    "> \n",
    ">\n",
    "\n",
    "![WstWorld](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1569578233461&di=4adfa7597fb380e7cc0e67190bbd7605&imgtype=0&src=http%3A%2F%2Fs1.sinaimg.cn%2Flarge%2F006eYYfyzy76cmpG3Yb1f)\n",
    "\n",
    "> \n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这一部分，需要各位同学首先定义自己的语言。 大家可以先想一个应用场景，然后在这个场景下，定义语法。例如：\n",
    "\n",
    "在西部世界里，一个”人类“的语言可以定义为：\n",
    "``` \n",
    "human = \"\"\"\n",
    "human = 自己 寻找 活动\n",
    "自己 = 我 | 俺 | 我们 \n",
    "寻找 = 看看 | 找找 | 想找点\n",
    "活动 = 乐子 | 玩的\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "一个“接待员”的语言可以定义为\n",
    "```\n",
    "host = \"\"\"\n",
    "host = 寒暄 报数 询问 业务相关 结尾 \n",
    "报数 = 我是 数字 号 ,\n",
    "数字 = 单个数字 | 数字 单个数字 \n",
    "单个数字 = 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 \n",
    "寒暄 = 称谓 打招呼 | 打招呼\n",
    "称谓 = 人称 ,\n",
    "人称 = 先生 | 女士 | 小朋友\n",
    "打招呼 = 你好 | 您好 \n",
    "询问 = 请问你要 | 您需要\n",
    "业务相关 = 玩玩 具体业务\n",
    "玩玩 = 耍一耍 | 玩一玩\n",
    "具体业务 = 喝酒 | 打牌 | 打猎 | 赌博\n",
    "结尾 = 吗？\"\"\"\n",
    "\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请定义你自己的语法: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一个语法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "invite = '''\n",
    "invite => 问候 ， 本人 询问 代称 内容 ， 结束语\n",
    "问候 => 称呼 | 称呼 打招呼 | 打招呼\n",
    "打招呼 => 你好 | 早啊\n",
    "称呼 => 小 姓氏 | 姓氏 人称 | 老 姓氏\n",
    "姓氏 => 张 | 刘 | 李 | 白 | 高 | 怀特\n",
    "人称 => 先生 | 小姐 | 女士 | 大哥 | 大爷\n",
    "本人 => 我 | 俺 | 咱 | 爸爸\n",
    "询问 => 想 邀约\n",
    "邀约 => 邀请 | 约 | 跟 | 喊\n",
    "代称 => 你 | 您\n",
    "内容 => 和我 活动 | 一起 活动 | 活动\n",
    "活动 => 吃个饭 | 打篮球 | 去滑雪 | 看电影\n",
    "结束语 => 可以吗？ | 有时间吗？ | 有空么？\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **评阅点**： 是否提出了和课程上区别较大的语法结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二个语法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = '''\n",
    "evaluation => item_evaluation | person_evaluation\n",
    "item_evaluation => pronoun_phrase 是 article adj* item comment\n",
    "person_evaluation => pronoun_phrase 是 particle padj* 的 role comment\n",
    "pronoun_phrase => pronoun | pronoun extent\n",
    "pronoun => 这 | 那 | 它 | 他 | 她 | 我 | 你\n",
    "extent => 简直 | 居然 | 果然 | 可能 | 估计 | 真的\n",
    "article => 一个 | 一部 | 一项\n",
    "particle => 一个 | 一位\n",
    "role => 人 | 人物 | 大佬 | 神人 | 老师 | 学生 | 警察\n",
    "adj* => adj 的 | adj 的 | adj 、 adj*\n",
    "adj => 唯美 | 文艺 | 厚重 | 传奇式 | 气势磅礴 | 细腻 | 雷人\n",
    "item => 电影 | 影片 | 电视剧 | 作品 | 剧\n",
    "padj* => padj | padj | padj 、 padj*\n",
    "padj => 内向 | 外向 | 出色 | 和蔼 | 阳光 | 开朗 | 阴暗 | 邪恶 | 善良\n",
    "comment => 。 | ， compliment\n",
    "compliment => lol | compliment ，lol | extend compliment\n",
    "lol => 哈哈 | 哈哈 lol\n",
    "compliment => 史无前例 | 乏善可陈 | 无力吐槽 | 简直了\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **评阅点**：是否和上一个语法区别比较大"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: 然后，使用自己之前定义的generate函数，使用此函数生成句子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_grammar(grammar_str: str, target, split = '=>'):\n",
    "    generated_grammar = {}\n",
    "    for line in grammar_str.split('\\n'):\n",
    "        if not line:\n",
    "            continue\n",
    "        expression, formula = line.split(split)\n",
    "        \n",
    "        formulas = formula.split('|')\n",
    "        \n",
    "        formulas = [f.split() for f in formulas]\n",
    "        \n",
    "        generated_grammar[expression.strip()] = formulas\n",
    "        \n",
    "    return generated_grammar\n",
    "\n",
    "def generate_by_grammar(grammar: dict, target: str):\n",
    "    if target not in grammar:\n",
    "        return target\n",
    "    expr = random.choice(grammar[target])\n",
    "    \n",
    "    return ''.join(generate_by_grammar(grammar, t) for t in expr)\n",
    "\n",
    "def generate(grammar_str, split, target):\n",
    "    grammar = generate_grammar(grammar_str, target, split)\n",
    "    return generate_by_grammar(grammar, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'怀特小姐，我想喊您和我去滑雪，有时间吗？'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(invite, split='=>', target='invite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'那简直是一部厚重、文艺、雷人的电影，史无前例'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(evaluation, split='=>', target='evaluation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: 然后，定义一个函数，generate_n，将generate扩展，使其能够生成n个句子:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_n(grammar_str, split, target, n):\n",
    "    for i in range(n):\n",
    "        print(generate(grammar_str, split, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你是一个善良的老师。\n",
      "我是一位开朗、阴暗、开朗的人，无力吐槽\n",
      "它是一个气势磅礴的剧，简直了\n",
      "他可能是一部开朗、善良、开朗的人物，无力吐槽\n",
      "他果然是一位唯美的影片。\n",
      "我真的是一个外向的大佬。\n",
      "它是一个善良、阳光、开朗、和蔼、开朗的人，乏善可陈\n",
      "我是一部传奇式、气势磅礴的剧。\n",
      "他是一位善良、阳光、和蔼的人物，乏善可陈\n",
      "我可能是一项厚重、细腻、文艺的影片，简直了\n"
     ]
    }
   ],
   "source": [
    "generate_n(evaluation, '=>', 'evaluation', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **评阅点**; 运行代码，观察是否能够生成多个句子"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 使用新数据源完成语言模型的训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按照我们上文中定义的`prob_2`函数，我们更换一个文本数据源，获得新的Language Model:\n",
    "\n",
    "1. 下载文本数据集（你可以在以下数据集中任选一个，也可以两个都使用）\n",
    "    + 可选数据集1，保险行业问询对话集： https://github.com/Computing-Intelligence/insuranceqa-corpus-zh/raw/release/corpus/pool/train.txt.gz\n",
    "    + 可选数据集2：豆瓣评论数据集：https://github.com/Computing-Intelligence/datasource/raw/master/movie_comments.csv\n",
    "2. 修改代码，获得新的**2-gram**语言模型\n",
    "    + 进行文本清洗，获得所有的纯文本\n",
    "    + 将这些文本进行切词\n",
    "    + 送入之前定义的语言模型中，判断文本的合理程度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from collections import Counter\n",
    "import re\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**读取train.txt数据，数据格式有问题，无法直接使用read_csv读取，使用分行读取并切分的方式读入**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = []\n",
    "with open('./train.txt', 'r', encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        cols = line.strip().split(\" ++$++ \")\n",
    "        data_1.append(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = pd.DataFrame(data_1, columns=['index','spec','cn','en'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>spec</th>\n",
       "      <th>cn</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>disability-insurance</td>\n",
       "      <td>法律要求残疾保险吗？</td>\n",
       "      <td>Is  Disability  Insurance  Required  By  Law?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>life-insurance</td>\n",
       "      <td>债权人可以在死后人寿保险吗？</td>\n",
       "      <td>Can  Creditors  Take  Life  Insurance  After  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>renters-insurance</td>\n",
       "      <td>旅行者保险有租赁保险吗？</td>\n",
       "      <td>Does  Travelers  Insurance  Have  Renters  Ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>auto-insurance</td>\n",
       "      <td>我可以开一辆没有保险的新车吗？</td>\n",
       "      <td>Can  I  Drive  A  New  Car  Home  Without  Ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>life-insurance</td>\n",
       "      <td>人寿保险的现金转出价值是否应纳税？</td>\n",
       "      <td>Is  The  Cash  Surrender  Value  Of  Life  Ins...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  index                  spec                 cn  \\\n",
       "0     0  disability-insurance         法律要求残疾保险吗？   \n",
       "1     1        life-insurance     债权人可以在死后人寿保险吗？   \n",
       "2     2     renters-insurance       旅行者保险有租赁保险吗？   \n",
       "3     3        auto-insurance    我可以开一辆没有保险的新车吗？   \n",
       "4     4        life-insurance  人寿保险的现金转出价值是否应纳税？   \n",
       "\n",
       "                                                  en  \n",
       "0      Is  Disability  Insurance  Required  By  Law?  \n",
       "1  Can  Creditors  Take  Life  Insurance  After  ...  \n",
       "2  Does  Travelers  Insurance  Have  Renters  Ins...  \n",
       "3  Can  I  Drive  A  New  Car  Home  Without  Ins...  \n",
       "4  Is  The  Cash  Surrender  Value  Of  Life  Ins...  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12889 entries, 0 to 12888\n",
      "Data columns (total 4 columns):\n",
      "index    12889 non-null object\n",
      "spec     12889 non-null object\n",
      "cn       12889 non-null object\n",
      "en       12889 non-null object\n",
      "dtypes: object(4)\n",
      "memory usage: 402.9+ KB\n"
     ]
    }
   ],
   "source": [
    "data_1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**读取movie_comments.csv数据，格式整齐，直接用read_csv读取**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_2 = pd.read_csv('./movie_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>name</th>\n",
       "      <th>comment</th>\n",
       "      <th>star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>吴京意淫到了脑残的地步，看了恶心想吐</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>首映礼看的。太恐怖了这个电影，不讲道理的，完全就是吴京在实现他这个小粉红的英雄梦。各种装备轮...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>吴京的炒作水平不输冯小刚，但小刚至少不会用主旋律来炒作…吴京让人看了不舒服，为了主旋律而主旋...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>凭良心说，好看到不像《战狼1》的续集，完虐《湄公河行动》。</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>中二得很</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                                        link name  \\\n",
       "0  1  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "1  2  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "2  3  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "3  4  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "4  5  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "\n",
       "                                             comment star  \n",
       "0                                 吴京意淫到了脑残的地步，看了恶心想吐    1  \n",
       "1  首映礼看的。太恐怖了这个电影，不讲道理的，完全就是吴京在实现他这个小粉红的英雄梦。各种装备轮...    2  \n",
       "2  吴京的炒作水平不输冯小刚，但小刚至少不会用主旋律来炒作…吴京让人看了不舒服，为了主旋律而主旋...    2  \n",
       "3                      凭良心说，好看到不像《战狼1》的续集，完虐《湄公河行动》。    4  \n",
       "4                                               中二得很    1  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 261497 entries, 0 to 261496\n",
      "Data columns (total 5 columns):\n",
      "id         261497 non-null object\n",
      "link       261497 non-null object\n",
      "name       261497 non-null object\n",
      "comment    261495 non-null object\n",
      "star       261497 non-null object\n",
      "dtypes: object(5)\n",
      "memory usage: 10.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data_2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**取出两份数据中所需文字，组合成语言模型使用的数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = list(data_1['cn']) + list(data_2['comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "274386"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_1) + len(data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "274386"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'法律要求残疾保险吗？'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[2008.10.04]其实没看懂，这片到底想说什么呢？不过我挺喜欢那种氛围的，还有女主角有爱。'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all[40000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**清洗，去除标点符号**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(string):\n",
    "    return re.findall('\\w+', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean = [''.join(tokenize(str(line))) for line in data_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "274386"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'法律要求残疾保险吗'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20081004其实没看懂这片到底想说什么呢不过我挺喜欢那种氛围的还有女主角有爱'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean[40000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**切词**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(data):\n",
    "    tokens = []\n",
    "    for i, line in enumerate(data):\n",
    "        if i % 5000 == 0:\n",
    "            print(\"%d lines done.\" % i)\n",
    "        tokens += list(jieba.cut(line))\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 lines done.\n",
      "5000 lines done.\n",
      "10000 lines done.\n",
      "15000 lines done.\n",
      "20000 lines done.\n",
      "25000 lines done.\n",
      "30000 lines done.\n",
      "35000 lines done.\n",
      "40000 lines done.\n",
      "45000 lines done.\n",
      "50000 lines done.\n",
      "55000 lines done.\n",
      "60000 lines done.\n",
      "65000 lines done.\n",
      "70000 lines done.\n",
      "75000 lines done.\n",
      "80000 lines done.\n",
      "85000 lines done.\n",
      "90000 lines done.\n",
      "95000 lines done.\n",
      "100000 lines done.\n",
      "105000 lines done.\n",
      "110000 lines done.\n",
      "115000 lines done.\n",
      "120000 lines done.\n",
      "125000 lines done.\n",
      "130000 lines done.\n",
      "135000 lines done.\n",
      "140000 lines done.\n",
      "145000 lines done.\n",
      "150000 lines done.\n",
      "155000 lines done.\n",
      "160000 lines done.\n",
      "165000 lines done.\n",
      "170000 lines done.\n",
      "175000 lines done.\n",
      "180000 lines done.\n",
      "185000 lines done.\n",
      "190000 lines done.\n",
      "195000 lines done.\n",
      "200000 lines done.\n",
      "205000 lines done.\n",
      "210000 lines done.\n",
      "215000 lines done.\n",
      "220000 lines done.\n",
      "225000 lines done.\n",
      "230000 lines done.\n",
      "235000 lines done.\n",
      "240000 lines done.\n",
      "245000 lines done.\n",
      "250000 lines done.\n",
      "255000 lines done.\n",
      "260000 lines done.\n",
      "265000 lines done.\n",
      "270000 lines done.\n"
     ]
    }
   ],
   "source": [
    "tokens = get_tokens(data_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "切分后共 4566594 个词语。\n"
     ]
    }
   ],
   "source": [
    "print(\"切分后共 %d 个词语。\" % len(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**存取分词后的数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_dump = json.dumps(tokens)\n",
    "with open(\"assigment_tokens.txt\", \"w\") as f:\n",
    "    f.write(token_dump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新读取tokens的方法\n",
    "def reload_tokens(file_name='assigment_tokens.txt'):\n",
    "    f=open(file_name)\n",
    "    tokens = f.read()\n",
    "    tokens = json.loads(tokens)\n",
    "    f.close()\n",
    "    return tokens\n",
    "tokens = reload_tokens()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**统计词频**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_count = Counter(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_2_gram = [''.join(tokens[i:i+2]) for i in range(len(tokens[:-2]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['法律', '要求', '残疾', '保险', '吗', '债权人', '可以', '在', '死', '后', '人寿保险']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['法律要求', '要求残疾', '残疾保险', '保险吗', '吗债权人', '债权人可以', '可以在', '在死', '死后', '后人寿保险']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_2_gram[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_count_2 = Counter(tokens_2_gram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**语言模型**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P(word) = #word / total\n",
    "# 如果word在语料库中不存在，则返回默认值 1 / total，避免整句最终概率的乘积(或条件概率的分母)为0\n",
    "def prob(word):\n",
    "    if word in words_count:\n",
    "        return words_count[word] / len(tokens)\n",
    "    else:\n",
    "        return 1 / len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p(w1w2) = #w1w2 / total_2_gram\n",
    "# 使用 p(w2|w1) = p(w1w2) / p(w1)\n",
    "# 如果w1w2在语料库中不存在，则返回默认值 1 / total_2_gram，避免整句最终概率的乘积为0\n",
    "def prob_2(w1, w2):\n",
    "    combine = w1 + w2\n",
    "    if combine in words_count_2:\n",
    "        return words_count_2[combine] / len(tokens_2_gram) / prob(w1)\n",
    "    else:\n",
    "        return 1 / len(tokens_2_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 p(w1w2w3w4) = p(w1) * p(w2|w1) * p(w3|w2) * p(w4|w3)\n",
    "# 也可以用 p(w1w2w3w4) = p(w1|w2) * p(w2|w3) * p(w3|w4) * p(w4), prob_2要改为p(w1|w2) = p(w1w2) / p(w2)\n",
    "def get_sentence_prob(sentence):\n",
    "    # 去除句子中的标点和换行\n",
    "    sentence = ''.join(tokenize(str(sentence)))\n",
    "    if not sentence:\n",
    "        return 0\n",
    "    # 分词\n",
    "    words = list(jieba.cut(sentence))\n",
    "    probability = prob(words[0])\n",
    "    for i,w1 in enumerate(words[:-1]):\n",
    "        w2 = words[i + 1]\n",
    "        p_w1_w2 = prob_2(w1, w2)\n",
    "        probability *= p_w1_w2\n",
    "        \n",
    "    return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000190076017268012"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob('今天')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "明天晚上请你吃大餐，我们一起吃苹果 is more possible\n",
      "---- 今天晚上请你吃大餐，我们一起吃日料 with probility 1.1031952197695134e-34\n",
      "---- 明天晚上请你吃大餐，我们一起吃苹果 with probility 1.3238342637234158e-34\n",
      "真是一只好看的小猫 is more possible\n",
      "---- 真事一只好看的小猫 with probility 3.2432689222356134e-25\n",
      "---- 真是一只好看的小猫 with probility 1.3464259921936156e-19\n",
      "今晚我去吃火锅 is more possible\n",
      "---- 今晚我去吃火锅 with probility 2.2595957456740328e-13\n",
      "---- 今晚火锅去吃我 with probility 6.998482729418668e-24\n",
      "养乐多绿来一杯 is more possible\n",
      "---- 洋葱奶昔来一杯 with probility 2.064246837208314e-23\n",
      "---- 养乐多绿来一杯 with probility 1.0500819061904638e-20\n"
     ]
    }
   ],
   "source": [
    "need_compared = [\n",
    "    \"今天晚上请你吃大餐，我们一起吃日料 明天晚上请你吃大餐，我们一起吃苹果\",\n",
    "    \"真事一只好看的小猫 真是一只好看的小猫\",\n",
    "    \"今晚我去吃火锅 今晚火锅去吃我\",\n",
    "    \"洋葱奶昔来一杯 养乐多绿来一杯\"\n",
    "]\n",
    "\n",
    "for s in need_compared:\n",
    "    s1, s2 = s.split()\n",
    "    p1, p2 = get_sentence_prob(s1), get_sentence_prob(s2)\n",
    "    \n",
    "    better = s1 if p1 > p2 else s2\n",
    "    \n",
    "    print('{} is more possible'.format(better))\n",
    "    print('-'*4 + ' {} with probility {}'.format(s1, p1))\n",
    "    print('-'*4 + ' {} with probility {}'.format(s2, p2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试结果一般，不如课上用的语料，全数据的情况下可以全部判断正确。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **评阅点** 1. 是否使用了新的数据集； 2. csv(txt)数据是否正确解析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 获得最优质的的语言"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当我们能够生成随机的语言并且能判断之后，我们就可以生成更加合理的语言了。请定义 generate_best 函数，该函数输入一个语法 + 语言模型，能够生成**n**个句子，并能选择一个最合理的句子: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提示，要实现这个函数，你需要Python的sorted函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 5]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([1, 3, 5, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个函数接受一个参数key，这个参数接受一个函数作为输入，例如"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 4), (2, 5), (4, 4), (5, 0)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(2, 5), (1, 4), (5, 0), (4, 4)], key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "能够让list按照第0个元素进行排序."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 0), (1, 4), (4, 4), (2, 5)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(2, 5), (1, 4), (5, 0), (4, 4)], key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "能够让list按照第1个元素进行排序."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 5), (1, 4), (4, 4), (5, 0)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(2, 5), (1, 4), (5, 0), (4, 4)], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "能够让list按照第1个元素进行排序, 但是是递减的顺序。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据语法直接生成一批语句，对每个句子计算出现概率，从中选取top-k（或根据分位数选取），  \n",
    "最后使用randome.choice从结果中随机选取一句返回。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_best(grammar_str, split, target, rounds=10, top_k=3):\n",
    "    '''\n",
    "    grammar_str: 语法结构字符串，\n",
    "    split: expression和content的分隔符，\n",
    "    target: 语法开头标记，\n",
    "    rounds：随机生成候选语句的数目，\n",
    "    top_k：生成最终语句随机选取范围的大小\n",
    "    '''\n",
    "    # 随机生成语句\n",
    "    sentences = []\n",
    "    for i in range(rounds):\n",
    "        sentence = generate(grammar_str, split, target)\n",
    "        # 计算语句概率，将语句和对应概率加入列表\n",
    "        probability = get_sentence_prob(sentence)\n",
    "        sentences.append((sentence, probability))\n",
    "    \n",
    "    # 按概率大小排序\n",
    "    sentences = sorted(sentences, key = lambda s : s[1])\n",
    "    \n",
    "    # return sentences[0]\n",
    "\n",
    "    # 选取top-k\n",
    "    if top_k < rounds:\n",
    "        sentences = sentences[:top_k]\n",
    "    \n",
    "    # 随机选取一个句子进行返回\n",
    "    return random.choice(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('我简直是一位阳光、邪恶、和蔼的大佬，史无前例', 7.431651702362391e-42)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_best(evaluation, split='=>', target='evaluation', rounds=20, top_k= 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "好了，现在我们实现了自己的第一个AI模型，这个模型能够生成比较接近于人类的语言。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **评阅点**： 是否使用 lambda 语法进行排序"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: 这个模型有什么问题？ 你准备如何提升？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:   \n",
    "1、对于不在语料库中的词语处理比较简单，如果语法中大量的词都不在其中的话，会导致所有句子的概率很小，而且彼此都相差不多，无法判断最优结果  \n",
    "2、没有对同义词等特殊关系做处理，比如语料库里有喜欢，测试数据里有喜爱，并不会提升这句话的概率  \n",
    "3、类似模型应该是都会受到数据量的影响，数据量越大，囊括的语料和语法越多，最后的结果也就越好。  \n",
    "4、文本生成过程对前文考虑不足，只关注前一个词语，有时产生的句子中会有很多重复的词语，可以尝试增大n-gram中的n，或者在选择语法分支/词语时加入部分规则判断？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**评阅点**: 是否提出了比较实际的问题，例如OOV问题，例如数据量，例如变成 3-gram问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 以下内容为可选部分，对于绝大多数同学，能完成以上的项目已经很优秀了，下边的内容如果你还有精力可以试试，但不是必须的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. (Optional) 完成基于Pattern Match的语句问答\n",
    "> 我们的GitHub仓库中，有一个assignment-01-optional-pattern-match，这个难度较大，感兴趣的同学可以挑战一下。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 5. (Optional) 完成阿兰图灵机器智能原始论文的阅读\n",
    "1. 请阅读阿兰图灵关于机器智能的原始论文：https://github.com/Computing-Intelligence/References/blob/master/AI%20%26%20Machine%20Learning/Computer%20Machinery%20and%20Intelligence.pdf \n",
    "2. 并按照GitHub仓库中的论文阅读模板，填写完毕后发送给我: mqgao@kaikeba.com 谢谢"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各位同学，我们已经完成了自己的第一个AI模型，大家对人工智能可能已经有了一些感觉，人工智能的核心就是，我们如何设计一个模型、程序，在外部的输入变化的时候，我们的程序不变，依然能够解决问题。人工智能是一个很大的领域，目前大家所熟知的深度学习只是其中一小部分，之后也肯定会有更多的方法提出来，但是大家知道人工智能的目标，就知道了之后进步的方向。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，希望大家对AI不要有恐惧感，这个并不难，大家加油！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1561828422005&di=48d19c16afb6acc9180183a6116088ac&imgtype=0&src=http%3A%2F%2Fb-ssl.duitang.com%2Fuploads%2Fitem%2F201807%2F28%2F20180728150843_BECNF.thumb.224_0.jpeg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
